{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel Rocha Ruiz, MSc in Data Science and Business Analytics\n",
    "\n",
    "# Multi-Label Classification in Python\n",
    "\n",
    "Tutorials:\n",
    "- https://www.depends-on-the-definition.com/guide-to-multi-label-classification-with-neural-networks/\n",
    "- https://towardsdatascience.com/multi-label-image-classification-with-neural-network-keras-ddc1ab1afede\n",
    "- https://www.analyticsvidhya.com/blog/2019/04/predicting-movie-genres-nlp-multi-label-classification/\n",
    "- https://stackoverflow.com/questions/38246559/how-to-create-a-heat-map-in-python-that-ranges-from-green-to-red\n",
    "\n",
    "Dataset:\n",
    "- www.cs.cmu.edu/~ark/personas/data/MovieSummaries.tar.gz\n",
    "\n",
    "Summary:\n",
    "- In this exercise, we use Tensorflow to model neural networks and perform multi-label classification.\n",
    "- The dataset contains text data on many different movies. Our task is to create a model that correctly predicts the genre of each movie based on its summary. As each movie may have one genre ore more, this is multi-label classification (i.e. each genre is a label, and a movie may have more than one genre).\n",
    "\n",
    "- One technicality:\n",
    "    - Multi-class is choosing one exclusive category out of many;\n",
    "    - Multi-label is choosing at least one category out of many.\n",
    "    \n",
    "Notebooks:\n",
    "- In *notebook 01* we will have a look at the *metadata* to understand a bit more about the labels.\n",
    "- In *notebook 02* we will clean the text data of movie plots, and create a dataset that we can use in model training.\n",
    "- In *notebook 03* we will train a baseline model using a logistic regression.\n",
    "- In *notebook 04* we will finally train the neural network.\n",
    "\n",
    "# Set-up\n",
    "## Environment\n",
    "- First, create the *tf_env* environment following the instructions in the README.\n",
    "- Alternatively, you can use an environment of your own that has tensorflow installed.\n",
    "\n",
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a few tweaks\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import packages\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "# neural networks\n",
    "from tensorflow import keras\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# text processing\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.functions import *\n",
    "\n",
    "# graphs\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# maths\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Let's load the dataset prepared in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41793, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23890098</th>\n",
       "      <td>shlykov hard working taxi driver lyosha saxoph...</td>\n",
       "      <td>[114, 359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31186339</th>\n",
       "      <td>nation panem consists wealthy capitol twelve p...</td>\n",
       "      <td>[2, 300, 5, 114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20663735</th>\n",
       "      <td>poovalli induchoodan sentenced six years priso...</td>\n",
       "      <td>[232, 46, 2, 114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231378</th>\n",
       "      <td>lemon drop kid new york city swindler illegall...</td>\n",
       "      <td>[75, 302]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595909</th>\n",
       "      <td>seventh day adventist church pastor michael ch...</td>\n",
       "      <td>[98, 359, 109, 114, 93]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          x  \\\n",
       "movie_id                                                      \n",
       "23890098  shlykov hard working taxi driver lyosha saxoph...   \n",
       "31186339  nation panem consists wealthy capitol twelve p...   \n",
       "20663735  poovalli induchoodan sentenced six years priso...   \n",
       "2231378   lemon drop kid new york city swindler illegall...   \n",
       "595909    seventh day adventist church pastor michael ch...   \n",
       "\n",
       "                                y  \n",
       "movie_id                           \n",
       "23890098               [114, 359]  \n",
       "31186339         [2, 300, 5, 114]  \n",
       "20663735        [232, 46, 2, 114]  \n",
       "2231378                 [75, 302]  \n",
       "595909    [98, 359, 109, 114, 93]  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace path if different\n",
    "df = pd.read_parquet(\"../data/cleaned_dataset.parquet\")\n",
    "\n",
    "# for ease\n",
    "df.columns = [\"x\",\"y\"]\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formatting\n",
    "A few last-mile adjustements are needed:\n",
    "- The Y data needs to be converted into a sparse matrix. This conversion doesn't spill information, so it's performed on the whole Y data at once.\n",
    "- The X data featurized with TF-IDF. This conversion could potentially spill information. So, it's calibrated on the training data, and only then applied to the validation data, to avoid an spillover (i.e. bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelBinarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Y data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m multilabel_binarizer \u001b[38;5;241m=\u001b[39m \u001b[43mMultiLabelBinarizer\u001b[49m()\n\u001b[0;32m      3\u001b[0m multilabel_binarizer\u001b[38;5;241m.\u001b[39mfit(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m multilabel_binarizer\u001b[38;5;241m.\u001b[39mtransform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiLabelBinarizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Y data\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df['y'])\n",
    "y = multilabel_binarizer.transform(df['y'])\n",
    "\n",
    "# train-val split\n",
    "xtrain, xval, ytrain, yval = train_test_split(df['x'], y, test_size=0.2, random_state=42)\n",
    "print(\"X Training data:\", xtrain.shape)\n",
    "print(\"X Validation data:\", xval.shape)\n",
    "print(\"Y Training data:\", ytrain.shape)\n",
    "print(\"Y Validation data:\", yval.shape)\n",
    "\n",
    "# X data\n",
    "# create TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Softmax:\n",
    "- The softmax is a generalization of the *logistic*.\n",
    "- The sum of the probabilities of the different labels add 1.\n",
    "\n",
    "Sigmoid:\n",
    "- The sigmoid assumes independence between the labels.\n",
    "    - If a movie is classifying a movie as *label1* doesn't change it's probability of also being classified as *label2*.\n",
    "    - So, the probabilities of different labels do not add 1.\n",
    "    - Hence, it is more suited for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2547572  0.01268361 0.0400573  0.69250188]\n",
      "[0.88079708 0.26894142 0.53742985 0.95257413]\n"
     ]
    }
   ],
   "source": [
    "def softmax(scores):\n",
    "    exp=np.exp(scores)\n",
    "    scores=exp/np.sum(exp)\n",
    "    return scores\n",
    "\n",
    "def sigmoid(scores):\n",
    "    scores=np.negative(scores)\n",
    "    exp=np.exp(scores)\n",
    "    scores=1/(1+exp)\n",
    "    return scores\n",
    "\n",
    "sample = [2, -1, .15, 3]\n",
    "print(softmax(sample))\n",
    "print(sigmoid(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 classes -> 1 output node for each class\n",
    "nn = keras.models.Sequential()\n",
    "nn.add(keras.layers.Dense(10, activation='relu', input_shape=(10,)))\n",
    "nn.add(keras.layers.Dense(5, activation='sigmoid'))\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "# Multi-Class Classification: Final Layer = Softmax\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=5, strides=2, activation='relu', input_shape=(268, 182, 3)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=3, strides=1, activation='relu'))       \n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Multi-Label Classification: Final Layer = Sigmoid\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=5, strides=2, activation='relu', input_shape=(268, 182, 3)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=3, strides=1, activation='relu'))       \n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Dataset fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 48 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 182 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 214 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 245 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Action', 'Drama')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31540448604823657"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4378137883178906"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie:  The Boys Next Door \n",
      "Predicted genre:  [()]\n",
      "Actual genre:  ['Crime Fiction', 'Thriller', 'Drama', 'Indie'] \n",
      "\n",
      "Movie:  Formosa Betrayed \n",
      "Predicted genre:  [('Action', 'Thriller')]\n",
      "Actual genre:  ['Crime Fiction', 'Thriller', 'Mystery', 'Period piece', 'Drama', 'Political thriller', 'Crime Thriller', 'Political drama'] \n",
      "\n",
      "Movie:  Isn't Life Wonderful \n",
      "Predicted genre:  [('Drama',)]\n",
      "Actual genre:  ['Silent film', 'Drama', 'Indie', 'Black-and-white'] \n",
      "\n",
      "Movie:  Belle Starr \n",
      "Predicted genre:  [('Drama',)]\n",
      "Actual genre:  ['Western'] \n",
      "\n",
      "Movie:  Single Room Furnished \n",
      "Predicted genre:  [('Drama', 'Romance Film')]\n",
      "Actual genre:  ['Drama'] \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
