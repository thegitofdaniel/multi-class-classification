{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel Rocha Ruiz, MSc in Data Science and Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Label Classification in Python\n",
    "\n",
    "Tutorials:\n",
    "- https://www.depends-on-the-definition.com/guide-to-multi-label-classification-with-neural-networks/\n",
    "- https://towardsdatascience.com/multi-label-image-classification-with-neural-network-keras-ddc1ab1afede\n",
    "- https://www.analyticsvidhya.com/blog/2019/04/predicting-movie-genres-nlp-multi-label-classification/\n",
    "\n",
    "Dataset:\n",
    "- www.cs.cmu.edu/~ark/personas/data/MovieSummaries.tar.gz\n",
    "\n",
    "Summary:\n",
    "- In this exercise, we use Tensorflow to model neural networks and perform multi-label classification.\n",
    "- The dataset contains text data on many different movies. Our task is to create a model that correctly predicts the genre of each movie based on its summary. As each movie may have one genre ore more, this is multi-label classification (i.e. each genre is a label, and a movie may have more than one genre). \n",
    "\n",
    "\n",
    "- One technicality:\n",
    "    - Multi-class is choosing one exclusive category out of many;\n",
    "    - Multi-label is choosing at least one category out of many."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n",
    "\n",
    "## Select the adequate environment.\n",
    "- First, if not done yet, create the *tf_env* environment following the instructions in the README.\n",
    "- Alternatively, you can use an environment of your own that has tensorflow installed.\n",
    "\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural networks\n",
    "from tensorflow import keras\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# text processing\n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# graphs\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# maths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "Let's load the dataset prepared in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41793, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shlykov hard working taxi driver lyosha saxoph...</td>\n",
       "      <td>[114, 359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nation panem consists wealthy capitol twelve p...</td>\n",
       "      <td>[2, 300, 5, 114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poovalli induchoodan sentenced six years priso...</td>\n",
       "      <td>[232, 46, 2, 114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon drop kid new york city swindler illegall...</td>\n",
       "      <td>[75, 302]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seventh day adventist church pastor michael ch...</td>\n",
       "      <td>[98, 359, 109, 114, 93]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x                        y\n",
       "0  shlykov hard working taxi driver lyosha saxoph...               [114, 359]\n",
       "1  nation panem consists wealthy capitol twelve p...         [2, 300, 5, 114]\n",
       "2  poovalli induchoodan sentenced six years priso...        [232, 46, 2, 114]\n",
       "3  lemon drop kid new york city swindler illegall...                [75, 302]\n",
       "4  seventh day adventist church pastor michael ch...  [98, 359, 109, 114, 93]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace path if different\n",
    "df = pd.read_parquet(\"data/cleaned_dataset.parquet\")\n",
    "\n",
    "# for ease\n",
    "df.columns = [\"x\",\"y\"]\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Baseline Prediction\n",
    "First, we train a logistic regression, that we will use as baseline.\n",
    "\n",
    "## Data Formatting\n",
    "A few last-mile adjustements are needed:\n",
    "- The Y data needs to be converted into a sparse matrix. This conversion doesn't spill information, so it's performed on the whole Y data at once.\n",
    "- The X data featurized with TF-IDF. This conversion could potentially spill information. So, it's calibrated on the training data, and only then applied to the validation data, to avoid an spillover (i.e. bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y data\n",
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df['y'])\n",
    "\n",
    "# transform target variable\n",
    "y = multilabel_binarizer.transform(df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training data: (33434,)\n",
      "X Validation data: (8359,)\n",
      "Y Training data: (33434, 363)\n",
      "Y Validation data: (8359, 363)\n"
     ]
    }
   ],
   "source": [
    "# train-val split\n",
    "xtrain, xval, ytrain, yval = train_test_split(df['x'], y, test_size=0.2, random_state=42)\n",
    "print(\"X Training data:\", xtrain.shape)\n",
    "print(\"X Validation data:\", xval.shape)\n",
    "print(\"Y Training data:\", ytrain.shape)\n",
    "print(\"Y Validation data:\", yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X data\n",
    "# create TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Classifier\n",
    "\n",
    "Steps:\n",
    "- For each label, we train a logistic regression. So, we will train 363 different logistic regressions.\n",
    "- The output of each logistic regression is evaluated agains a threshold, an the result has a boolean interpretation (e.g. Is this the summary of an Action movie?).\n",
    "- These will be combined with the *OneVsRestClassifier* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 61 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 74 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 243 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 245 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 259 is present in all training examples.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\multiclass.py:79: UserWarning: Label not 292 is present in all training examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "CPU times: total: 2min 38s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create classifier objects\n",
    "lr = LogisticRegression()\n",
    "clf = OneVsRestClassifier(lr)\n",
    "\n",
    "# fit model on train data\n",
    "clf.fit(xtrain_tfidf, ytrain)\n",
    "print(\"N-Classes\", clf.n_classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set, Default Threshold\n",
      "F1-Score: 0.3173826632013454\n",
      "Validation Set, Custom Threshold\n",
      "F1-Score: 0.44040165867143677\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# predictions for validation set\n",
    "print(\"Validation Set, Default Threshold\")\n",
    "y_pred = clf.predict(xval_tfidf)\n",
    "print(\"F1-Score:\", f1_score(yval, y_pred, average=\"micro\"))\n",
    "\n",
    "# predictions for validation set with custom threshold t\n",
    "print(\"Validation Set, Custom Threshold\")\n",
    "y_pred_prob = clf.predict_proba(xval_tfidf)\n",
    "t = 0.3\n",
    "y_pred_new = (y_pred_prob >= t).astype(int)\n",
    "print(\"F1-Score:\", f1_score(yval, y_pred_new, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shlykov hard working taxi driver lyosha saxoph...</td>\n",
       "      <td>[114, 359]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nation panem consists wealthy capitol twelve p...</td>\n",
       "      <td>[2, 300, 5, 114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poovalli induchoodan sentenced six years priso...</td>\n",
       "      <td>[232, 46, 2, 114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon drop kid new york city swindler illegall...</td>\n",
       "      <td>[75, 302]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seventh day adventist church pastor michael ch...</td>\n",
       "      <td>[98, 359, 109, 114, 93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42199</th>\n",
       "      <td>story reema young muslim schoolgirl malabar lo...</td>\n",
       "      <td>[63]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42200</th>\n",
       "      <td>hollywood director leo andreyev looks photogra...</td>\n",
       "      <td>[352, 196, 261, 43, 306, 114, 255]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42201</th>\n",
       "      <td>american luthier focuses randy parsons transfo...</td>\n",
       "      <td>[305, 39, 110, 231]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42202</th>\n",
       "      <td>abdur rehman khan middle aged dry fruit seller...</td>\n",
       "      <td>[114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42203</th>\n",
       "      <td>operation dynamo taken place newly conquered f...</td>\n",
       "      <td>[75]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       x  \\\n",
       "0      shlykov hard working taxi driver lyosha saxoph...   \n",
       "1      nation panem consists wealthy capitol twelve p...   \n",
       "2      poovalli induchoodan sentenced six years priso...   \n",
       "3      lemon drop kid new york city swindler illegall...   \n",
       "4      seventh day adventist church pastor michael ch...   \n",
       "...                                                  ...   \n",
       "42199  story reema young muslim schoolgirl malabar lo...   \n",
       "42200  hollywood director leo andreyev looks photogra...   \n",
       "42201  american luthier focuses randy parsons transfo...   \n",
       "42202  abdur rehman khan middle aged dry fruit seller...   \n",
       "42203  operation dynamo taken place newly conquered f...   \n",
       "\n",
       "                                        y  \n",
       "0                              [114, 359]  \n",
       "1                        [2, 300, 5, 114]  \n",
       "2                       [232, 46, 2, 114]  \n",
       "3                               [75, 302]  \n",
       "4                 [98, 359, 109, 114, 93]  \n",
       "...                                   ...  \n",
       "42199                                [63]  \n",
       "42200  [352, 196, 261, 43, 306, 114, 255]  \n",
       "42201                 [305, 39, 110, 231]  \n",
       "42202                               [114]  \n",
       "42203                                [75]  \n",
       "\n",
       "[41793 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q = clean_text(q)\n",
    "    q = remove_stopwords(q)\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    q_pred = clf.predict(q_vec)\n",
    "    return multilabel_binarizer.inverse_transform(q_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Softmax:\n",
    "- The softmax is a generalization of the *logistic*.\n",
    "- The sum of the probabilities of the different labels add 1.\n",
    "\n",
    "Sigmoid:\n",
    "- The sigmoid assumes independence between the labels.\n",
    "    - If a movie is classifying a movie as *label1* doesn't change it's probability of also being classified as *label2*.\n",
    "    - So, the probabilities of different labels do not add 1.\n",
    "    - Hence, it is more suited for multi-label classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2547572  0.01268361 0.0400573  0.69250188]\n",
      "[0.88079708 0.26894142 0.53742985 0.95257413]\n"
     ]
    }
   ],
   "source": [
    "def softmax(scores):\n",
    "    exp=np.exp(scores)\n",
    "    scores=exp/np.sum(exp)\n",
    "    return scores\n",
    "\n",
    "def sigmoid(scores):\n",
    "    scores=np.negative(scores)\n",
    "    exp=np.exp(scores)\n",
    "    scores=1/(1+exp)\n",
    "    return scores\n",
    "\n",
    "sample = [2, -1, .15, 3]\n",
    "print(softmax(sample))\n",
    "print(sigmoid(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 classes -> 1 output node for each class\n",
    "\n",
    "nn = keras.models.Sequential()\n",
    "nn.add(keras.layers.Dense(10, activation='relu', input_shape=(10,)))\n",
    "nn.add(keras.layers.Dense(5, activation='sigmoid'))\n",
    "\n",
    "nn.compile(optimizer='adam', loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "# Multi-Class Classification\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=5, strides=2, activation='relu', input_shape=(268, 182, 3)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=3, strides=1, activation='relu'))       \n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='softmax'))   # Final Layer using Softmax\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Multi-Label Classification\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=5, strides=2, activation='relu', input_shape=(268, 182, 3)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=3, strides=1, activation='relu'))       \n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='sigmoid'))   # Final Layer using Softmax\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Dataset fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 48 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 182 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 214 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\drr19\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 245 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Action', 'Drama')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_binarizer.inverse_transform(y_pred)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31540448604823657"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4378137883178906"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie:  The Boys Next Door \n",
      "Predicted genre:  [()]\n",
      "Actual genre:  ['Crime Fiction', 'Thriller', 'Drama', 'Indie'] \n",
      "\n",
      "Movie:  Formosa Betrayed \n",
      "Predicted genre:  [('Action', 'Thriller')]\n",
      "Actual genre:  ['Crime Fiction', 'Thriller', 'Mystery', 'Period piece', 'Drama', 'Political thriller', 'Crime Thriller', 'Political drama'] \n",
      "\n",
      "Movie:  Isn't Life Wonderful \n",
      "Predicted genre:  [('Drama',)]\n",
      "Actual genre:  ['Silent film', 'Drama', 'Indie', 'Black-and-white'] \n",
      "\n",
      "Movie:  Belle Starr \n",
      "Predicted genre:  [('Drama',)]\n",
      "Actual genre:  ['Western'] \n",
      "\n",
      "Movie:  Single Room Furnished \n",
      "Predicted genre:  [('Drama', 'Romance Film')]\n",
      "Actual genre:  ['Drama'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): \n",
    "    k = xval.sample(1).index[0]\n",
    "    print(\"Movie: \", movies_new['movie_name'][k]\n",
    "          ,\"\\nPredicted genre: \", infer_tags(xval[k])\n",
    "          ,\"Actual genre\": ,movies_new['genre_new'][k]\n",
    "          , \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
